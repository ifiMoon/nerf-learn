# 颠覆传统三维重建之nerf(七)---pytorch-nerf模型创建1之位置编码
> 读核心create_nerf函数的代码的get_embedder

### 一. 带着问题去读代码
1. 相机参数怎么读取和处理？
2. 最终输出的数据格式？

### 二. create_nerf的核心函数
```
def create_nerf(args):
    
    embed_fn, input_ch = get_embedder(args.multires, args.i_embed)

    input_ch_views = 0
    embeddirs_fn = None
    if args.use_viewdirs:
        embeddirs_fn, input_ch_views = get_embedder(args.multires_views, args.i_embed)
    output_ch = 5 if args.N_importance > 0 else 4
    skips = [4]
    model = NeRF(D=args.netdepth, W=args.netwidth,
                 input_ch=input_ch, output_ch=output_ch, skips=skips,
                 input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs).to(device)
    grad_vars = list(model.parameters())

    model_fine = None
    if args.N_importance > 0:
        model_fine = NeRF(D=args.netdepth_fine, W=args.netwidth_fine,
                          input_ch=input_ch, output_ch=output_ch, skips=skips,
                          input_ch_views=input_ch_views, use_viewdirs=args.use_viewdirs).to(device)
        grad_vars += list(model_fine.parameters())

    network_query_fn = lambda inputs, viewdirs, network_fn : run_network(inputs, viewdirs, network_fn,
                                                                embed_fn=embed_fn,
                                                                embeddirs_fn=embeddirs_fn,
                                                                netchunk=args.netchunk)

    # Create optimizer
    optimizer = torch.optim.Adam(params=grad_vars, lr=args.lrate, betas=(0.9, 0.999))

    # Load checkpoints
    #略

    render_kwargs_train = {
        'network_query_fn' : network_query_fn,
        'perturb' : args.perturb,
        'N_importance' : args.N_importance,
        'network_fine' : model_fine,
        'N_samples' : args.N_samples,
        'network_fn' : model,
        'use_viewdirs' : args.use_viewdirs,
        'white_bkgd' : args.white_bkgd,
        'raw_noise_std' : args.raw_noise_std,
    }

    # NDC only good for LLFF-style forward facing data
    if args.dataset_type != 'llff' or args.no_ndc:
        print('Not ndc!')
        render_kwargs_train['ndc'] = False
        render_kwargs_train['lindisp'] = args.lindisp

    render_kwargs_test = {k : render_kwargs_train[k] for k in render_kwargs_train}
    render_kwargs_test['perturb'] = False
    render_kwargs_test['raw_noise_std'] = 0.

    return render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer
```

### 三. 位置编码get_embedder
embed_fn, input_ch = get_embedder(args.multires, args.i_embed)
1. 输入
    - multires(default=10)：log2 of max freq for positional encoding (3D location)
    - i_embed(default=0)：set 0 for default positional encoding, -1 for none
    - multires_views(default=4)：log2 of max freq for positional encoding (2D direction)
2. 输出
    - embed_fn：编码函数
    - input_ch = 63：编码输出的通道数
3. 分析：
    - 对输入的3通道数据，进行multires次torch.sin和torch.cos变化。
    - 算一下输出：输入的原值输出3 + 3*10*2 = 63。 10次sin + 次cos。
    - sin和cos是x * freq。freq = 2的0-9次方。freq=[1,2,4,...,512];
    - embed_fn =  [
            x[0], x[1], x[2], 
            sin(1  *x[0]), cos(1  *x[0]), sin(1  *x[1]), cos(1  **x[1]), sin(1  **x[2]), cos(1  **x[2]),
            sin(2  *x[0]), cos(2  *x[0]), sin(2  *x[1]), cos(2  **x[1]), sin(2  **x[2]), cos(2  **x[2]),
            sin(4  *x[0]), cos(4  *x[0]), sin(4  *x[1]), cos(4  **x[1]), sin(4  **x[2]), cos(4  **x[2]),
            sin(8  *x[0]), cos(8  *x[0]), sin(8  *x[1]), cos(8  **x[1]), sin(8  **x[2]), cos(8  **x[2]),
            sin(16 *x[0]), cos(16 *x[0]), sin(16 *x[1]), cos(16 **x[1]), sin(16 **x[2]), cos(16 **x[2]),
            sin(32 *x[0]), cos(32 *x[0]), sin(32 *x[1]), cos(32 **x[1]), sin(32 **x[2]), cos(32 **x[2]),
            sin(64 *x[0]), cos(64 *x[0]), sin(64 *x[1]), cos(64 **x[1]), sin(64 **x[2]), cos(64 **x[2]),
            sin(128*x[0]), cos(128*x[0]), sin(128*x[1]), cos(128**x[1]), sin(128**x[2]), cos(128**x[2]),
            sin(256*x[0]), cos(256*x[0]), sin(256*x[1]), cos(256**x[1]), sin(256**x[2]), cos(256**x[2]),
            sin(512*x[0]), cos(512*x[0]), sin(512*x[1]), cos(512**x[1]), sin(512**x[2]), cos(512**x[2])]

### 具体实现，可以不看，直接拷贝
```
def get_embedder(multires, i=0):
    if i == -1:
        return nn.Identity(), 3
    
    embed_kwargs = {
                'include_input' : True,
                'input_dims' : 3,
                'max_freq_log2' : multires-1,
                'num_freqs' : multires,
                'log_sampling' : True,
                'periodic_fns' : [torch.sin, torch.cos],
    }
    
    embedder_obj = Embedder(**embed_kwargs)
    embed = lambda x, eo=embedder_obj : eo.embed(x)
    return embed, embedder_obj.out_dim
```
```
# Positional encoding (section 5.1)
class Embedder:
    def __init__(self, **kwargs):
        self.kwargs = kwargs
        self.create_embedding_fn()
        
    def create_embedding_fn(self):
        embed_fns = []
        d = self.kwargs['input_dims']
        out_dim = 0
        if self.kwargs['include_input']:
            embed_fns.append(lambda x : x)
            out_dim += d
            
        max_freq = self.kwargs['max_freq_log2']
        N_freqs = self.kwargs['num_freqs']
        
        if self.kwargs['log_sampling']:
            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)
        else:
            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)
            
        for freq in freq_bands:
            for p_fn in self.kwargs['periodic_fns']:
                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))
                out_dim += d
                    
        self.embed_fns = embed_fns
        self.out_dim = out_dim
        
    def embed(self, inputs):
        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)
```