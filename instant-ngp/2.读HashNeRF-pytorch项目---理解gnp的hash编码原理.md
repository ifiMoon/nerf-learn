# 读HashNeRF-pytorch项目---理解gnp的hash编码原理

### 一. 提出问题
1. 怎么进行位置编码？
2. 神经网络怎么简化？

### 二. 代码修改
1. run_nerf.py的config_parser增加了两个选项，用来切换编码方式
    --i_embed            set 1 for hashed embedding, 0 for default positional encoding, 2 for spherical
    --i_embed_views      set 1 for hashed embedding, 0 for default positional encoding, 2 for spherical
    --finest_res         finest resolultion for hashed embedding
    --log2_hashmap_size  log2 of hashmap size
    --sparse-loss-weight learning rate
    --tv-loss-weight     learning rate
2. 加载数据返回bounding_box：load_llff_data，load_blender_data
    ```
     #load_blender.py
     bounding_box = get_bbox3d_for_blenderobj(metas["train"], H, W, near=2.0, far=6.0)
   ```
3. run_nerf.py：create_nerf创建hash编码和神经网络   
    - 如果是hash编码：要返回参数来训练：embedding_params
    - 如果是hash编码：就创建NeRFSmall网络
4. 增长hash_encoding.py：定义哈希编码class HashEmbedder和球面编码class SHEncoder
    - 编码本身就是神经网络
    - 默认参数
       - n_levels=16, 
       - n_features_per_level=2,
       - log2_hashmap_size=19, 
       - base_resolution=16, 
       - finest_resolution=512
5. run_nerf_helpers.py中NeRFSmall的定义，就更少的层数

### 三. 就是看懂class HashEmbedder
```
class HashEmbedder
```